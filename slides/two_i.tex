% see: https://groups.google.com/forum/?fromgroups#!topic/comp.text.tex/s6z9Ult_zds
\makeatletter\let\ifGm@compatii\relax\makeatother 
\documentclass[10pt,t]{beamer}
\usefonttheme{professionalfonts}
\usefonttheme{serif}
\PassOptionsToPackage{pdfpagemode=FullScreen}{hyperref}
\PassOptionsToPackage{usenames,dvipsnames}{color}
% \DeclareGraphicsRule{*}{mps}{*}{}
\usepackage{../linalgjh}
\usepackage{present}
\usepackage{xr}\externaldocument{../vs1} % read refs from .aux file
\usepackage{catchfilebetweentags}
\usepackage{etoolbox} % from http://tex.stackexchange.com/questions/40699/input-only-part-of-a-file-using-catchfilebetweentags-package
\makeatletter
\patchcmd{\CatchFBT@Fin@l}{\endlinechar\m@ne}{}
  {}{\typeout{Unsuccessful patch!}}
\makeatother

\mode<presentation>
{
  \usetheme{boxes}
  \setbeamercovered{invisible}
  \setbeamertemplate{navigation symbols}{} 
}
\addheadbox{filler}{\ }  % create extra space at top of slide 
\hypersetup{colorlinks=true,linkcolor=blue} 

\title[Vector Space Definition] % (optional, use only with long paper titles)
{Two.I Vector Space Definition}

\author{\textit{Linear Algebra} \\ {\small Jim Hef{}feron}}
\institute{
  \texttt{http://joshua.smcvt.edu/linearalgebra}
}
\date{}


\subject{Vector Space Definition}
% This is only inserted into the PDF information catalog. Can be left
% out. 

\begin{document}
\begin{frame}
  \titlepage
\end{frame}

% =============================================
% \begin{frame}{Reduced Echelon Form} 
% \end{frame}



% ..... Two.I.1 .....
\section{Definition and examples}
% \begin{frame}{Vector space}
% \df[def:VecSpace]
% \ExecuteMetaData[../vs1.tex]{df:VectorSpace0}

% \pause
% \ExecuteMetaData[../vs1.tex]{df:VectorSpace1}

% \pause
% \ExecuteMetaData[../vs1.tex]{df:VectorSpace2}
% \end{frame}



% ..........
\begin{frame}{Vector space}
\df[def:VecSpace]
A \definend{vector space}\index{vector space!definition}
(over \( \Re \)) consists of a set \( V \) along with
two operations `+' and `\( \cdot \)' subject to the conditions
that for all vectors \( \vec{v},\vec{w},\vec{u}\in V \), 
and all \definend{scalars}
\( r,s\in\Re \):
\begin{enumerate}
\item the set $V$ is \definend{closed} under
  vector addition, that is, 
  \( \vec{v}+\vec{w}\in V \)
\item vector addition is commutative
  \( \vec{v}+\vec{w}=\vec{w}+\vec{v} \) 
\item vector addition is associative
  \( (\vec{v}+\vec{w})+\vec{u}=\vec{v}+(\vec{w}+\vec{u}) \)
\item there is a \definend{zero vector}
    \( \zero\in V \) such that
    \( \vec{v}+\zero=\vec{v}\, \) for all \( \vec{v}\in V\/ \)
\item each \( \vec{v}\in V \) has an
    \definend{additive inverse}
    \( \vec{w}\in V \) such that \( \vec{w}+\vec{v}=\zero \)
\pause\item  the set $V$ is closed under
    scalar multiplication, that is, 
   \( r\cdot\vec{v}\in V \)
\item addition of scalars distributes over scalar multiplication
 \( (r+s)\cdot\vec{v}=r\cdot\vec{v}+s\cdot\vec{v} \)
\item scalar multiplication distributes over vector addition
  \( r\cdot(\vec{v}+\vec{w})=r\cdot\vec{v}+r\cdot\vec{w} \)
\item ordinary multipication of scalars associates with 
  scalar multiplication \( (rs)\cdot\vec{v} =r\cdot(s\cdot\vec{v}) \)
\item multiplication by the scalar~$1$ is the 
  identity operation \( 1\cdot\vec{v}=\vec{v} \).
\end{enumerate}
\end{frame}



% ..........
\begin{frame}
\ex
Consider the set of row vectors
consisting of all multiples of $\rowvec{1 &2}$.
\begin{equation*}
  V=\set{\rowvec{a  &2a}\suchthat a\in\Re}
\end{equation*}
Some members of $V$ are $\rowvec{4 &8}$, $\rowvec{1/2 &1}$,
$\rowvec{-100 &-200}$, and $\rowvec{0 &0}$.

\pause
This $V$
is a vector space under the natural addition
\begin{equation*}
  \rowvec{a_1 &2a_1}+\rowvec{a_2 &2a_2}
  =
  \rowvec{a_1+a_2 &2a_1+2a_2}
\end{equation*}
and scalar multiplication operations.
\begin{equation*}
  r\rowvec{a_1 &2a_1}
  =
  \rowvec{ra_1 &2ra_1}
\end{equation*}
To verify that, we will check each of the ten conditions.
Because this is the first time through the definition,
we will verify these at length.
\end{frame}\begin{frame}
We first check closure under addition~(1),
that the sum of two members of $V$
is also a member of $V$.
Take $\vec{v}$ and  $\vec{w}$ to be members of $V$.
\begin{equation*}
  \vec{v}=\rowvec{v_1 &2v_1}
  \qquad
  \vec{w}=\rowvec{w_1 &2w_1}  
\end{equation*}
Then their sum
\begin{equation*}
  \vec{v}+\vec{w}=
  \rowvec{v_1+w_1 &2v_1+2w_1}
\end{equation*} 
is also a member of $V$ because its second entry is twice its first.

\pause
Condition~(2), commutativity of addition, is straightforward.
The sums in the two orders are
\begin{equation*}
  \vec{v}+\vec{w}=\rowvec{v_1+w_1 &2(v_1+w_1)}
\end{equation*}
and
\begin{equation*}
  \vec{w}+\vec{v}
  =
  \rowvec{w_1+v_1 &2(w_1+v_1)}  
\end{equation*}
and the two are equal because 
$v_1+w_1$ equals $w_1+v_1$, as both are sums of real numbers
and real number addition is commutative.
\end{frame}\begin{frame}
Condition~(3), associativity of addition, is like the prior one.
The left side is 
\begin{equation*}
  (\vec{v}+\vec{w})+\vec{u}=\rowvec{(v_1+w_1)+u_1 &(2v_1+2w_1)+2u_1}
\end{equation*}
while the right side is this.
\begin{equation*}
  \vec{v}+(\vec{w}+\vec{u})
  =
  \rowvec{v_1+(w_1+u_1) &2v_1+(2w_1+2u_1)}  
\end{equation*}
The two are equal because real number addition is associative 
$(v_1+w_1)+u_1=v_1+(w_1+u_1)$.

\pause
For condition~(4) we can just exhibit the member of $V$ with the desired 
property. 
So consider $\zero=\rowvec{0 &0}$.
It is a member of $V$ since its second component is twice its first.
Note that it is the required identity element with respect to addition. 
\begin{align*}
  \vec{v}+\zero
  &=\rowvec{v_1 &2v_1}+\rowvec{0  &0}     \\
  &=\rowvec{v_1 &2v_1}    \\
  &=\vec{v}
\end{align*}
\end{frame}\begin{frame}
Condition~(5), existence of an additive inverse, is also a matter of 
producing the desired element.
Given a member $\vec{v}=\rowvec{v_1 &2v_1}$ of $V$, consider
$\vec{w}=\rowvec{-v_1 &-2v_1}$.
Then $\vec{w}\in V$, and note that it cancels $\vec{v}$.
\begin{equation*}
  \vec{w}+\vec{v}=\rowvec{-v_1 &-2v_1}+\rowvec{v_1 &2v_1}=\zero
\end{equation*}

\pause
We finish by verifying the five conditions having to do with scalar multiplication.


Condition~(6) is closure under scalar multiplication.
Consider a scalar $r\in\Re$ and a vector $\vec{v}=\rowvec{v_1 &2v_1}\in V$.
The scalar multiple $r\vec{v}=\rowvec{rv_1 &r2v_1}$ is also a member
of $V$ because the second component is twice the first.

\pause
Condition~(7) is that 
real number addition distributes over scalar multiplication.
Let the scalars be $r,s\in\Re$, and 
let the vector be $\vec{v}=\rowvec{v_1 &2v_1}\in V$.
Here is the check.
\begin{align*}
  (r+s)\vec{v} &= \rowvec{(r+s)v_1 &(r+s)2v_1}               \\
               &=\rowvec{rv_1 &2rv_1}+\rowvec{sv_1 &2sv_1}   \\
               &=r\vec{v}+s\vec{v}
\end{align*}
\end{frame}\begin{frame}
For (8),
distributivity of vector addition over scalar multiplication,
take a scalar $r\in\Re$ and 
two vectors $\vec{v},\vec{w}\in V$.
\begin{align*}
  r(\vec{v}+\vec{w}) &=\rowvec{rv_1 &2rv_1}+\rowvec{rw_1 &2rw_1}   \\
                     &=\rowvec{rv_1+rw_1 &2rv_1+2rw_1}           \\
                     &=r\rowvec{v_1 &2v_1}+r\rowvec{w_1 &2w_1}   \\
                     &=r\vec{v}+r\vec{w}
\end{align*}

\pause
For condition~(9) suppose $r,s\in\Re$ and $\vec{v}=\rowvec{v_1 &2v_1}\in V$.
The left side is $(rs)\rowvec{v_1 &2v_1}=\rowvec{(rs)v_1 &(rs)2v_1}$, while the
right side is 
$r(s\rowvec{v_1 &2v_1})=r\rowvec{sv_1 &s2v_1}=\rowvec{r(sv_1) &r(s2v_1)}$.
The two are equal because
$(rs)v_1=r(sv_1)$ and $(rs)2v_1=r(s2v_1)$, 
as those are real number multiplications.   

\pause
Condition~(10) is simple:
$1\vec{v}=1\rowvec{v_1 &2v_1}=\rowvec{1\cdot v_1 &1\cdot 2v_1}=\vec{v}$
for any $\vec{v}\in V$.

\pause\medskip
Therefore the set
$V=\set{\rowvec{a  &2a}\suchthat a\in\Re}$
is a vector space under the natural addition and scalar multiplication 
operations.
\end{frame}




% ..........
\begin{frame}
\ex
The set $\Re^3$ is a vector space under the usual vector addition and
scalar multiplication operations.
\begin{equation*}
  \colvec{v_1 \\ v_2 \\ v_3}
  +\colvec{w_1 \\ w_2 \\ w_3}
  =\colvec{v_1+w_1 \\ v_2+w_2 \\ v_3+w_3}
  \quad\text{and}\quad
  r\colvec{v_1 \\ v_2 \\ v_3}
  =\colvec{rv_1 \\ rv_2 \\ rv_3}
\end{equation*}
To verify that, we will check the conditions (more briefly than 
for the prior example).

\pause
Condition~(1) is closure under addition.
This is clear because the only condition for membership
in the set $\Re^3$ is to be a three-tall vector of reals, and the sum of
two three-tall vectors of reals is also a three-tall vector of reals.

\pause
Condition~(2) is routine.
\begin{equation*}
  \vec{v}+\vec{w}
  =
  \colvec{v_1 \\ v_2 \\ v_3}
  +\colvec{w_1 \\ w_2 \\ w_3}
  =\colvec{v_1+w_1 \\ v_2+w_2 \\ v_3+w_3}
  =
  \colvec{w_1 \\ w_2 \\ w_3}
  +\colvec{v_1 \\ v_2 \\ v_3}
  =\vec{w}+\vec{v}
\end{equation*}
\end{frame}\begin{frame}
Condition~(3) is also a direct consequence of the related
real number property.
\begin{multline*}
  (\vec{v}+\vec{w})+\vec{u}
  =
  \colvec{v_1+w_1 \\ v_2+w_2 \\ v_3+w_3}
  +\colvec{u_1 \\ u_2 \\ u_3}
  =\colvec{v_1+w_1+u_1 \\ v_2+w_2+u_2 \\ v_3+w_3+u_3}        \\
  =
  \colvec{v_1 \\ v_2 \\ v_3}
  +\colvec{w_1+u_1 \\ w_2+u_2 \\ w_3+u_3}
  =\vec{v}+(\vec{w}+\vec{u})
\end{multline*}

\pause
For condition~(4) take the vector of $0$'s.
\begin{equation*}
  \colvec{0  \\ 0 \\ 0}+\colvec{v_1 \\ v_2 \\ v_3}=\colvec{v_1 \\ v_2 \\ v_3}
\end{equation*}
For condition~(5), given $\vec{v}\in\Re^3$, use  $\vec{w}=-1\vec{v}$
as the additive inverse.
\begin{equation*}
  \colvec{-v_1  \\ -v_2 \\ -v_3}+\colvec{v_1 \\ v_2 \\ v_3}=\colvec{0 \\ 0 \\ 0}
\end{equation*}
\end{frame}\begin{frame}
Condition~(6) is closure under scalar multiplication.
Let the scalar be $r\in\Re$ and the vector be $\vec{v}\in\Re^3$.
Then $r\vec{v}$ is a three-tall vector of reals, so $r\vec{v}\in\Re^3$.

\pause
Conditions~(7)
\begin{equation*}
  (r+s)\colvec{v_1 \\ v_2 \\ v_3}
  =\colvec{(r+s)v_1 \\ (r+s)v_2 \\ (r+s)v_3}
  =\colvec{rv_1+sv_1 \\ rv_2+sv_2 \\ rv_3+sv_3}
  =\colvec{rv_1 \\ rv_2 \\ rv_3}
  +\colvec{sv_1 \\ sv_2 \\ sv_3}
  =r\vec{v}+s\vec{v}  
\end{equation*}
and~(8)
\begin{equation*}
  r(\vec{v}+\vec{w})
  =r(\colvec{v_1 \\ v_2 \\ v_3}+\colvec{w_1 \\ w_2 \\ w_3})
  =r\colvec{v_1+w_1 \\ v_2+w_2 \\ v_3+w_3}
  =\colvec{rv_1+rw_1 \\ rv_2+rw_2 \\ rv_3+rw_3}
  % =\colvec{rv_1 \\ rv_2 \\ rv_3}
  % +\colvec{rw_1 \\ rw_2 \\ rw_3}
  =r\vec{v}+r\vec{w}  
\end{equation*}
are straightforward.
\end{frame}\begin{frame}
Condition~(9) is similar.
\begin{equation*}
  (rs)\colvec{v_1 \\ v_2 \\ v_3}
  =\colvec{(rs)v_1 \\ (rs)v_2 \\ (rs)v_3}
  =r\colvec{sv_1 \\ sv_2 \\ sv_3}
  =r(s\vec{v})  
\end{equation*}
And~(10) is also easy.
\begin{equation*}
  1\vec{v}
  =1\colvec{v_1 \\ v_2 \\ v_3}
  =\colvec{1\cdot v_1 \\ 1\cdot v_2 \\ 1\cdot v_3}
  =\colvec{v_1 \\ v_2 \\ v_3}
  =\vec{v} 
\end{equation*}

\pause\medskip
So the set $\Re^3$ is a vector space under the usual operations
of vector addition and scalar-vector multiplication.
\end{frame}




% ..........
\begin{frame}
\ex
This plane through the origin subset of $\Re^3$ 
\begin{equation*}
  P=\set{\colvec{x \\ y \\ z} \suchthat 2x+y+3z=0}  
\end{equation*}
is a vector space.
We will verify conditions~(1) and~(6)
(the others are exactly as in the prior example).

\pause
For (1) suppose that these are members of the plane
\begin{equation*}
  \vec{p}_1=\colvec{x_1 \\ y_1 \\ z_1}
  \quad
  \vec{p}_2=\colvec{x_2 \\ y_2 \\ z_2}
\end{equation*}
so that both $2x_1+y_1+3z_1=0$ and $2x_2+y_2+3z_2=0$.
Then the sum is 
\begin{equation*}
  \vec{p}_1+\vec{p}_2=\colvec{x_1+x_2 \\ y_1+y_2 \\ z_1+z_2}
\end{equation*}
and to verify that it is in the plane note that
$2(x_1+x_2)+(y_1+y_2)+3(z_1+z_2)=(2x_1+y_1+3z_1)+(2x_2+y_2+3z_2)=0$.
\end{frame}\begin{frame}
\begin{center}
  \includegraphics{asy/two_i_plane.pdf}    
\end{center}

For condition~(6) take a member of the plane
\begin{equation*}
  \vec{p}=\colvec{x_1 \\ y_1 \\ z_1}
  \qquad \text{such that $2x_1+y_1+3z_1=0$}
\end{equation*}
and multiply by a scalar $r\in\Re$. 
\begin{equation*}
  r\vec{p}=\colvec{rx_1 \\ ry_1 \\ rz_1}
\end{equation*}
Verify that $r\vec{p}$ is a member of the plane~$P$ with
$2(rx_1)+(ry_1)+3(rz_1)=r(2x_1+y_1+3z_1)=0$.
\end{frame}




% ..........
\begin{frame}
\ex
The set 
$\polyspace_2=\set{a_0+a_1x+a_2x^2 \suchthat a_0,a_1,a_2\in\Re}$
of quadratic polynomials
is a vector space under the usual operations of polynomial addition
\begin{equation*}
  (a_0+a_1x+a_2x^2)+(b_0+b_1x+b_2x^2)=(a_0+b_0)+(a_1+b_1)x+(a_2+b_2)x^2
\end{equation*}
and scalar multiplication.
\begin{equation*} 
r\cdot (a_0+a_1x+a_2x^2)=(ra_0)+(ra_1)x+(ra_2)x^2
\end{equation*}

We won't here check all the conditions but
in particular note that this space is closed: 
a linear combination of quadratic polynomials 
is a quadratic polynomial.
For instance, here is a sample combination in $\polyspace_2$:
\begin{equation*}
  4\cdot(1+2x+3x^2)-(1/5)\cdot (10+5x^2)
  =2+8x+11x^2
\end{equation*}
a linear combination of quadratic polynomials is a quadratic polynomial.
\end{frame}



\begin{frame}
\ex
The set of $\nbyn{3}$ matrices
\begin{equation*}
  \matspace_{\nbyn{3}}=\set{\begin{mat}
                            a_{1,1}  &a_{1,2} &a_{1,3} \\
                            a_{2,1}  &a_{2,2} &a_{2,3} \\
                            a_{3,1}  &a_{3,2} &a_{3,3}
                          \end{mat} 
                         \suchthat a_{i,j}\in\Re}
\end{equation*}
is a vector space under the usual matrix addition and scalar multiplication.
The check of the ten conditions is straightforward.

Here is a sample linear combination.
\begin{equation*}
  \begin{mat}
    1 &0 &1 \\
    2 &0 &2 \\
   -1 &3 &1/2
  \end{mat}
  -3\begin{mat}
    0 &0 &2 \\
    1 &1 &1 \\
    0 &4 &3/2
  \end{mat}
  =
  \begin{mat}
    1 &0  &-5 \\
   -1 &-3 &1 \\
   -1 &-9 &-4
  \end{mat}
\end{equation*}
\end{frame}


\begin{frame}
The empty set cannot be made a vector space, regardless of which operations
we use, because the definition requires that the space contains 
an additive identity.

\pause
\ex
The set consisting only of the two-tall zero vector
\begin{equation*}
  V=\set{\colvec{0  \\  0}}
\end{equation*}
is a vector space (under the usual vector addition and scalar multiplication
operations).
\begin{equation*}
  \colvec{0 \\ 0}+\colvec{0 \\ 0}=\colvec{0 \\ 0}
  \qquad
  r\cdot\colvec{0 \\ 0}=\colvec{0 \\ 0}
\end{equation*}

\df[df:TrivialVectorSpace]
\ExecuteMetaData[../vs1.tex]{df:TrivialVectorSpace}
\end{frame}




% ..........
\begin{frame}
\lm[lm:ElementaryPropertiesOfVectorSpaces]
\ExecuteMetaData[../vs1.tex]{lm:ElementaryPropertiesOfVectorSpaces}

\pause
\pf
\ExecuteMetaData[../vs1.tex]{pf:ElementaryPropertiesOfVectorSpaces0}
\qed
\end{frame}







\section{Subspaces and spanning sets}

% ..........
\begin{frame}{Subspace}
\df[df:Subspace]
\ExecuteMetaData[../vs1.tex]{df:Subspace}

\pause\medskip
\ExecuteMetaData[../vs1.tex]{ProperSubspace}

\pause
\ex
In the vector space $\Re^2$, the line $y=2x$ 
\begin{equation*}
  S=\set{\colvec{a \\ 2a} \suchthat a\in\Re}
   =\set{\colvec{1 \\ 2}a \suchthat a\in\Re}
\end{equation*}
is a subspace.
The operations, as required by the definition above, are the ones from $\Re^2$.
We could show it is a vector space by checking the ten conditions 
but the next result gives an easier way.

\pause
\ex
This subset of $\matspace_{\nbyn{2}}$ is a subspace. 
\begin{equation*}
  S=\set{\begin{mat}
           a  &b  \\
           a  &b
         \end{mat} \suchthat a,b\in\Re}
   =\set{\begin{mat}
           1  &0  \\
           1  &0
         \end{mat}a
         +\begin{mat}
           0  &1  \\
           0  &1
          \end{mat}b
         \suchthat a,b\in\Re}
\end{equation*}
As above, addition and scalar multiplication are the same as in 
$\matspace_{\nbyn{2}}$.
\end{frame}




% ..........
\begin{frame}
\ex
This is not a subspace of $\Re^3$.
\begin{equation*}
  T=\set{\colvec{x  \\ y  \\ z}\suchthat x+y+z=1}
\end{equation*}
It is a subset of $\Re^3$ but it is not a vector space.
One condition that it violates is that it is not closed under vector addition:
here are two elements of $T$ that sum to a vector that is not an element of 
$T$. 
\begin{equation*}
  \colvec{1  \\ 0  \\ 0}
  +\colvec{0 \\ 1 \\ 0}
  =\colvec{1 \\ 1 \\ 0}
\end{equation*}
(Another reason that it is not a vector space is that it does not satisfy
condition~(6).
Still another is that it does not contain the zero vector.)
\end{frame}




% ..........
\begin{frame}
\lm[th:SubspIffClosed]
\ExecuteMetaData[../vs1.tex]{lm:SubspIffClosed}

\pause\bigskip
\iftoggle{showallproofs}{
  \ExecuteMetaData[../vs1.tex]{pf:SubspIffClosed0}
}{
  The book has the full proof.
  Its idea is that if $V$ is a vector space with a subset $S$
  then many of the ten properties required for $S$ to be a 
  vector space are automatic.
  For instance, suppose that 
  $\vec{s}_1,\vec{s}_2\in S$ and consider commutativity 
  of addition: does $\vec{s}_1+\vec{s}_2$ equal $\vec{s}_2+\vec{s}_1$? 
  \pause
  Because the $+$ operation is inherited from $V$ and
  as sums of elements of~$V$ the two are equal
  $\vec{s}_1+\vec{s}_2=\vec{s}_2+\vec{s}_1$, 
  then provided $S$ is closed the two are equal in~$S$.

  \pause
  Many of the other nine conditions are also automatic.
  The only ones that need to be checked are the closure conditions.
  Both statements~(2) and~(3) above just combine the two closure conditions
  into a single one, to make the subspace verification faster.
}
\end{frame}
\iftoggle{showallproofs}{
  \begin{frame}
  \pf[th:SubspIffClosed]
  \ExecuteMetaData[../vs1.tex]{pf:SubspIffClosed1}

  \pause
  The conditions for scalar multiplication are similar.
  \qed
  \end{frame}
}{}




% ..........
\begin{frame}
\ex
The vector space of quadratic polynomials
$\polyspace_2=\set{a_0+a_1x+a_2x^2\suchthat a_0,a_1,a_2\in\Re}$ has a subspace
comprised of the linear polynomials
$L=\set{b_0+b_1x\suchthat b_0,b_1\in\Re}$.
By the prior result, to verify that we need only check 
closure under linear combinations of two members.
\begin{equation*}
  r(b_0+b_1x)+s(c_0+c_1x)=(rb_0+sc_0)+(rb_1+sc_1)x
\end{equation*}
The right side is a linear polynomial with real coefficients, and so is a 
member of $L$.
Thus $L$ is a subspace of $\polyspace_2$.

\pause
\ex
Another subspace of $\polyspace_2$ is the set of quadratic polynomials
having three equal coefficients.
\begin{equation*}
  M=\set{a+ax+ax^2\suchthat a\in\Re}
   =\set{(1+x+x^2)a\suchthat a\in\Re}
\end{equation*}
Verify that it is a subspace by
considering a linear combination of two of its members
(under the inherited operations).
\begin{equation*}
  r(a+ax+ax^2)+s(b+bx+bx^2)
  =(ra+sb)+(ra+sb)x+(ra+sb)x^2
\end{equation*}
The result is a quadratic polynomial with three equal coefficients  
and so $M$ is closed under linear combinations.
\end{frame}




% ..........
\begin{frame}
Each of the above subspace examples  
parametrizes the description.
For instance, with the prior example's 
$\set{a+ax+ax^2\suchthat a\in\Re}$ we brought out the
parameter by restating it as $\set{(1+x+x^2)a\suchthat a\in\Re}$.
% That's a key to understanding vector spaces.

\ex
This subset of $\Re^3$ is a plane.
\begin{equation*}
  P=\set{\colvec{x  \\ y  \\ z}\suchthat 2x-y+z=0}
\end{equation*}
We could
verify that it is a subspace by checking that it is closed under 
linear combination, as above.
However, that's easier if we first parametrize.
\pause
Solve the one-equation linear system
$2x-y+z=0$ to express the leading variable~$x$
in terms of the free variables $y$ and~$z$.
\begin{equation*}
  P=\set{\colvec{(1/2)y-(1/2)z  \\ y  \\ z}\suchthat y,z\in\Re}  
   =\set{\colvec{1/2 \\ 1 \\ 0}y+\colvec{-1/2 \\ 0 \\ 1 }z\suchthat y,z\in\Re}  
\end{equation*}
\end{frame}
\begin{frame}
\noindent With the parametrized description
\begin{equation*}
  P=\set{y\colvec{1/2 \\ 1 \\ 0}+z\colvec{-1/2 \\ 0 \\ 1 }\suchthat y,z\in\Re}  
  \tag{$*$}
\end{equation*}
showing the subspace is closed under linear combinations is straightforward
(here, $r_1,r_2\in\R$).
\begin{multline*}
  r_1\cdot\big(y_1\colvec{1/2 \\ 1 \\ 0}+z_1\colvec{-1/2 \\ 0 \\ 1 }\big)
  +r_2\cdot\big(y_2\colvec{1/2 \\ 1 \\ 0}+z_2\colvec{-1/2 \\ 0 \\ 1 }\big)
     \\
  =(r_1y_1+r_2y_2)\cdot\colvec{1/2 \\ 1 \\ 0}
     +(r_1z_1+r_2z_2)\cdot\colvec{-1/2 \\ 0 \\ 1 }
\end{multline*}
Line~($*$)
describes each member of $P$ as a linear combination of the two vectors.
Verifying that $P$ is closed then just involves taking a linear combination of 
linear combinations.
Of course, that gives a linear combination.
\end{frame}



\begin{frame}
\ex To show that this is a subspace of the space of 
two by two matrices $\matspace_{\nbyn{2}}$
\begin{equation*}
  Q = 
  \set{
    \begin{mat}
      a &b \\
      c &d
    \end{mat}
    \suchthat 
      \text{$a-b=0$ and $b-c=0$}}
\end{equation*}
treat that as a two-equation linear system and parametrize.
You get leading variables $a$ and~$b$, and free variables $c$ and~$d$.
\begin{equation*}
  Q = 
  \set{
    \begin{mat}
      c &c \\
      c &d
    \end{mat}
    \suchthat 
      c,d\in\Re}
  = 
  \set{
    c
    \begin{mat}
      1 &1 \\
      1 &0
    \end{mat}
    +d
    \begin{mat}
      0 &0 \\
      0 &1
    \end{mat}
    \suchthat 
      c,d\in\Re}
\end{equation*}
\pause
To show $Q$ is a subspace, use the lemma's clause~(2) by finding that a
linear combination of such matrices is such a matrix.
\begin{multline*}
    r_1\cdot\big(c_1
    \begin{mat}
      1 &1 \\
      1 &0
    \end{mat}
    +d_1
    \begin{mat}
      0 &0 \\
      0 &1
    \end{mat}
    \big)
    +r_2\cdot\big(c_2
    \begin{mat}
      1 &1 \\
      1 &0
    \end{mat}
    +d_2
    \begin{mat}
      0 &0 \\
      0 &1
    \end{mat}
    \big)
                                       \\
    =(r_1c_1+r_2c_2)\cdot
    \begin{mat}
      1 &1 \\
      1 &0
    \end{mat}
    +(r_1d_1+r_2d_2))
    \begin{mat}
      0 &0 \\
      0 &1
    \end{mat}
\end{multline*}
\end{frame}


% ..........
\begin{frame}{Span}
\df[df:Span]
\ExecuteMetaData[../vs1.tex]{df:Span}

\medskip
\ExecuteMetaData[../vs1.tex]{NotationForSpan}

\pause
\ex
Inside the vector space of all two-wide row vectors, the span of this 
one-element set
\begin{equation*}
  S=\set{\rowvec{1  &2}}
\end{equation*}
is this.
\begin{equation*}
  \spanof{S}
  =\set{\rowvec{a &2a}\suchthat a\in\Re}
  =\set{\rowvec{1 &2}a\suchthat a\in\Re}
\end{equation*}
\end{frame}




% ..........
\begin{frame}
\ex
This is a subset of $\Re^3$.
\begin{equation*}
  \hat{S}=\set{\colvec{1 \\ -1 \\ 0},
         \colvec{1 \\ 1 \\ 0}}
\end{equation*}
Any vector in the $xy$-plane is a member of the span $\spanof{S}$ because 
any such vector is a combination of the two;
for instance, this system has a solution
\begin{equation*}
  \colvec{3 \\ 2 \\ 0}=\colvec{1 \\ -1 \\ 0}c_1
                       +\colvec{1 \\ 1 \\ 0}c_2
\end{equation*}
(the top two rows gives a linear system with a unique solution).
\pause
But vectors not in the $xy$-plane are not in the span. 
For instance,
this system does not have a solution.
\begin{equation*}
  \colvec{-1 \\ -2 \\ -3}=\colvec{1 \\ -1 \\ 0}c_1
                       +\colvec{1 \\ 1 \\ 0}c_2
\end{equation*}
\end{frame}




% ..........
\begin{frame}
\lm[le:SpanIsASubsp]
\ExecuteMetaData[../vs1.tex]{lm:SpanIsASubsp}

\pause
\pf
\ExecuteMetaData[../vs1.tex]{pf:SpanIsASubsp}
\qed
\end{frame}
\begin{frame}
\ex
We can illustrate that a span is closed under linear combinations.
Where 
\begin{equation*}
  \hat{S}=\set{\colvec{1 \\ -1 \\ 0},
         \colvec{1 \\ 1 \\ 0}}\subset\Re^3
\end{equation*}
these are two elements of the span $\spanof{\hat{S}}$.
\begin{equation*}
  \vec{v}_1=5\cdot\colvec{1 \\ -1 \\ 0}
   +3\cdot\colvec{1 \\ 1 \\ 0}
  \qquad
  \vec{v}_2=-2\cdot\colvec{1 \\ -1 \\ 0}
    +10\cdot\colvec{1 \\ 1 \\ 0}
\end{equation*}
The linear combination $-3\vec{v}_1+7\vec{v_2}$
makes another element of the span.
\begin{equation*}
  -3\cdot\big( 5\colvec{1 \\ -1 \\ 0}
   +3\colvec{1 \\ 1 \\ 0}\big)
  +7\cdot\big(-2\colvec{1 \\ -1 \\ 0}
    +10\colvec{1 \\ 1 \\ 0}\big)
  =
  -29\cdot\colvec{1 \\ -1 \\ 0}
    +61\colvec{1 \\ 1 \\ 0}
\end{equation*}
This is just an instance of
the Linear Combination Lemma: a linear combination of 
linear combinations is a linear combination. 
\end{frame}


%...........................
% \begin{frame}
% \ExecuteMetaData[../gr3.tex]{GaussJordanReduction}
% \df[def:RedEchForm]
% 
% \end{frame}
\end{document}
